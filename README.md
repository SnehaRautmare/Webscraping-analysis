# Webpage Scraping and analysis
There are attached HTML pages from Wikipedia and task is to do something interesting with them

## Few ideas
- Extract all links from all pages and present them in a structured format (e.g. print a JSON document with all links)
- Download all images to a folder and print interesting statistics to get some insights (e.g. image width/height and size)
- Try to find the frequency of different word categories (nouns, adjectives,...) across all pages.
- Analyze the content in any other interesting way. Skillful visualization of your analysis is a plus!
